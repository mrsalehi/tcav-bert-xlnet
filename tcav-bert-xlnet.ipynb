{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Run_TCAV_1 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Z3XZRIvB4EBN"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "ggLxCYaH3dg7",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "# TCAV with BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "LfA4AYOM9EAF",
        "new_sheet": false,
        "outputId": "24498584-0f93-43d7-96f8-746ffee833fd",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Nov 28 13:19:06 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "GpTsxHl61xAK",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "3m43fKN94JT1",
        "new_sheet": false,
        "outputId": "f8a9adb4-5b63-4526-9be9-3b41c738f598",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "! pip install -q nltk\n",
        "! pip install -q transformers==2.1.1\n",
        "! pip install -q gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 317kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 43.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 44.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 860kB 47.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "_lCmwlQG12hB",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "Lh6zhFsj3dhA",
        "new_sheet": false,
        "outputId": "7c99beb2-be59-4632-b068-0442959b1a4f",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import gensim\n",
        "import uuid\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "from transformers import *\n",
        "import torch\n",
        "from google.colab import auth\n",
        "import transformers\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "fG_duFw115S1",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "W5dXSw9GBTYD",
        "new_sheet": false,
        "outputId": "41524707-4c7b-44f9-8846-f7a172c6232c",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "sYguf0fD_ybu",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "sJX18Wnj_0ZW",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "#TRAIN_PATH = 'imdb_reviews/train.csv'\n",
        "TRAIN_PATH = '/content/drive/My Drive/train.csv'\n",
        "DEVICE = 'cuda:0'\n",
        "\n",
        "#TEST_PATH = 'imdb_reviews/test.csv'\n",
        "TEST_PATH = '/content/drive/My Drive/test.csv'\n",
        "\n",
        "DEBUG = False\n",
        "VALIDATION = True  # Validation during fune-tuning XLNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "Z3XZRIvB4EBN",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "collapsed": true,
        "deletable": true,
        "id": "99tlDgXo4CMy",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "CACHE_DIR = 'cache'\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, pretrained_weights):\n",
        "      super(BERT, self).__init__()\n",
        "      self.bert_classifier = BertForSequenceClassification.from_pretrained(pretrained_weights, \n",
        "                                                                           cache_dir=CACHE_DIR)\n",
        "      self.representation = None\n",
        "      self.bert_classifier.bert.register_forward_hook(self.hook_fn)\n",
        "      self.bert_classifier.requires_grad_(True)\n",
        "    \n",
        "    def hook_fn(self, module, inupt, output):\n",
        "      self.representation = output\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, labels=None):\n",
        "      if labels is not None:\n",
        "        loss, logits = self.bert_classifier(input_ids=input_ids, labels=labels)\n",
        "      else:\n",
        "        out = self.bert_classifier(input_ids=input_ids)\n",
        "        logits = out[0]\n",
        "\n",
        "      preds = torch.argmax(logits, dim=-1)  # (batch_size, )\n",
        "\n",
        "      if labels is None:\n",
        "        return logits, preds, self.representation\n",
        "      else:\n",
        "        loss = nn.functional.cross_entropy(logits, labels)\n",
        "        return loss, logits, preds, self.representation\n",
        "\n",
        "    # def forward_from_representation(self, representation):\n",
        "    #   logits = self.bert.classifier(representation)  # (batch_size, num_labels)\n",
        "    #   preds = torch.argmax(logits, dim=-1)  # (batch_size, )\n",
        "    #   return preds, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "92QPGzLpcxFE",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### XLNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "XIKEoaIrcwWe",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "CACHE_DIR = 'cache'\n",
        "\n",
        "class XLNetClassifier(nn.Module):\n",
        "  def __init__(self, pretrained_weights):\n",
        "    super(XLNetClassifier, self).__init__()\n",
        "    self.xlnet_classifier = XLNetForSequenceClassification.from_pretrained(pretrained_weights, \n",
        "                                                                           cache_dir=CACHE_DIR)\n",
        "  \n",
        "    self.grad_representation = None\n",
        "    self.representation = None\n",
        "    \n",
        "    #self.xlnet_classifier.sequence_summary.register_forward_hook(self.forward_hook_fn)\n",
        "    #self.xlnet_classifier.sequence_summary.register_backward_hook(self.backward_hook_fn)\n",
        "\n",
        "    # using the representation of layer12 in the transformer\n",
        "    for name, module in self.xlnet_classifier.transformer.named_modules(): \n",
        "      if name == 'layer.12':\n",
        "        module.register_forward_hook(self.forward_hook_fn)\n",
        "        module.register_backward_hook(self.backward_hook_fn)\n",
        "\n",
        "    self.xlnet_classifier.requires_grad_(True)\n",
        "  \n",
        "  def forward_hook_fn(self, module, input, output):\n",
        "    self.representation = output\n",
        "\n",
        "  def backward_hook_fn(self, module, grad_input, grad_output):\n",
        "    self.grad_representation = grad_output[0]\n",
        "\n",
        "  def forward(self, input_ids: torch.Tensor, labels=None):\n",
        "    if labels is not None:\n",
        "      loss, logits = self.xlnet_classifier(input_ids=input_ids, labels=labels)\n",
        "    else:\n",
        "      out = self.xlnet_classifier(input_ids=input_ids)\n",
        "      logits = out[0]\n",
        "\n",
        "    preds = torch.argmax(logits, dim=-1)  # (batch_size, )\n",
        "\n",
        "    if labels is None:\n",
        "      return logits, preds, self.representation\n",
        "    else:\n",
        "      loss = nn.functional.cross_entropy(logits, labels)\n",
        "      return loss, logits, preds, self.representation\n",
        "\n",
        "  def forward_from_representation(self, representation: torch.Tensor):\n",
        "    #classifier = nn.Sequential(self.xlnet_classifier.sequence_summary, self.xlnet_classifier.logits_proj)\n",
        "    #logits = classifier(representation)  # (batch_size, num_labels)\n",
        "    \n",
        "    preds = torch.argmax(logits, dim=-1)  # (batch_size, )\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "pARCo_3zSzTH",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### Creating an instance of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "cellView": "form",
        "colab_type": "code",
        "deletable": true,
        "id": "kNspR9XQK61i",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "#@title Model\n",
        "model = \"xlnet\" #@param [\"bert\", \"xlnet\"]\n",
        "model_type = \"large\" #@param [\"large\", \"base\"]\n",
        "\n",
        "\n",
        "if model == 'xlnet':\n",
        "  if model_type == 'large':\n",
        "    pretrained_weights = 'xlnet-large-cased'\n",
        "  elif model_type == 'base':\n",
        "    pretrained_weights = 'xlnet-base-cased'\n",
        "  model = XLNetClassifier(pretrained_weights)\n",
        "  tokenizer = XLNetTokenizer.from_pretrained(pretrained_weights)\n",
        "elif model == 'bert':\n",
        "  if model_type == 'large':\n",
        "    pretrained_weights = 'bert-large-cased'\n",
        "  elif model_type == 'base':\n",
        "    pretrained_weights = 'bert-base-cased'\n",
        "  model = BERTClassifier(pretrained_weights)\n",
        "  tokenizer = BERTTokenizer.from_pretrained(pretrained_weights)\n",
        "\n",
        "model.to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "8Is75QsJ3dhH",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### Preprocessing training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "EwAfFV6N3dhI",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "\n",
        "if DEBUG:\n",
        "  train_df = train_df[:50]\n",
        "\n",
        "# X, y\n",
        "X = train_df['sentence'].tolist()\n",
        "y = train_df['polarity'].tolist()\n",
        "\n",
        "# training and validation set for fine-tuning BERT\n",
        "idxs = np.arange(len(X))\n",
        "\n",
        "if VALIDATION:\n",
        "  train_idxs, val_idxs = train_test_split(idxs, train_size=0.9)\n",
        "  X_train = [X[idx] for idx in train_idxs]\n",
        "  y_train = [y[idx] for idx in train_idxs]\n",
        "  X_val = [X[idx] for idx in val_idxs]\n",
        "  y_val = [y[idx] for idx in val_idxs]\n",
        "else:\n",
        "  train_idxs = idxs\n",
        "  X_train = [X[idx] for idx in train_idxs]\n",
        "  y_train = [y[idx] for idx in train_idxs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "OX535ZuU3dhK",
        "new_sheet": false,
        "outputId": "75f4b70e-db3a-4812-f861-cb60e1b640c2",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "b6P7QxWi_CiP",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "-vni04pR3dhQ",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "def pad(sents, pad_token=0):\n",
        "  sents_padded = []\n",
        "  longest = max([len(sent) for sent in sents])\n",
        "  sents_padded = list(map(lambda sent: sent+[pad_token]*(longest-len(sent)), sents))\n",
        "\n",
        "  return sents_padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "dmZFH2dp3dhS",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "def batch_iter(X, y, tokenizer, batch_size):\n",
        "  assert len(X) == len(y)\n",
        "\n",
        "  idxs = np.arange(len(X))\n",
        "  np.random.shuffle(idxs)\n",
        "\n",
        "  for i in range(0, len(X), batch_size):\n",
        "    X_batch = [X[idx] for idx in idxs[i:i+batch_size]]\n",
        "    y_batch = [y[idx] for idx in idxs[i:i+batch_size]]\n",
        "      \n",
        "    X_batch = [tokenizer.encode(sentence[:128], add_special_tokens=True) for sentence in X_batch]\n",
        "    X_batch = torch.tensor(pad(X_batch))\n",
        "    y_batch = torch.tensor(y_batch)\n",
        "      \n",
        "    yield X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "yifptZTEZOH7",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### Accuracy on validation set w.o. fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "pgXEwIqAYooj",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "n_samples = n_correct = 0\n",
        "\n",
        "for X, y in batch_iter(X_train, y_train, tokenizer, batch_size=8):\n",
        "  n_samples += len(X)\n",
        "  _, preds, _ = model(X)\n",
        "  n_correct += torch.sum(preds == y).item()\n",
        "\n",
        "val_acc = n_correct / n_samples\n",
        "print('val acc: %f' % val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "eL8wwbF03dhW",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### Fine-tuning on dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "EtVbf9wp2F_3",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "##### Training config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "cellView": "form",
        "colab_type": "code",
        "deletable": true,
        "id": "XzWU6GxbdHw4",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "learning_rate = 2e-5 #@param {type:\"number\"}\n",
        "use_scheduler = False #@param {type:\"boolean\"}\n",
        "warmup_steps = 500 #@param {type:\"integer\"}\n",
        "t_total = 0 #@param {type:\"integer\"}\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "if use_scheduler:\n",
        "  scheduler = WarmupLinearSchedule(optimizer=optimizer, warmup_steps=warmup_steps, t_total=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "htLlM3_p2KFN",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "##### Main training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "cellView": "form",
        "colab_type": "code",
        "deletable": true,
        "id": "RZNMB6t93dhY",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "#@title Train (fine-tuning)\n",
        "n_epochs = 20 #@param {type:\"integer\"}\n",
        "batch_size = 8 #@param {type:\"integer\"}\n",
        "val_every = 500 #@param {type:\"integer\"}\n",
        "def fine_tune(X_train, y_train, X_val=None, y_val=None, n_epochs=3, batch_size=32, val_every=100):\n",
        "  print('Running with n_epochs %d, batch_size %d, val_every %d' % (n_epochs, batch_size, val_every))\n",
        "  iteration = 0\n",
        "  val_accs = []\n",
        "  running_loss, running_num_iter = 0., 0\n",
        "  print(optimizer.param_groups[0]['lr'])\n",
        "  for i in range(n_epochs):\n",
        "    epoch_loss = 0.\n",
        "\n",
        "    for X, y in batch_iter(X_train, y_train, tokenizer, batch_size=batch_size):\n",
        "      iteration += 1\n",
        "      running_num_iter += 1\n",
        "\n",
        "      if iteration % 50 == 0:\n",
        "        print('iteration', iteration)\n",
        "        print(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "      X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "      optimizer.zero_grad()\n",
        "      loss, _, _, _ = model(X, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "          \n",
        "      epoch_loss += loss.item()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      if iteration % val_every == 0 and VALIDATION:\n",
        "        model.eval()\n",
        "        print('loss:', running_loss / running_num_iter)\n",
        "              \n",
        "        running_loss = 0.\n",
        "        running_num_iter = 0\n",
        "\n",
        "        print('begin validation...')\n",
        "        n_correct = n_samples = 0\n",
        "        for X, y in batch_iter(X_val, y_val, tokenizer, batch_size=batch_size):\n",
        "          n_samples += len(X)\n",
        "          X = X.to(DEVICE)\n",
        "          y = y.to(DEVICE)\n",
        "          _, preds, _ = model(X)\n",
        "          n_correct += torch.sum(preds == y).item()\n",
        "              \n",
        "        val_acc = n_correct / n_samples\n",
        "        print('val acc: %f' % val_acc)\n",
        "              \n",
        "        if len(val_accs) == 0 or max(val_accs) < val_acc:\n",
        "          print('Saving a checkpoint...')\n",
        "          if use_scheduler:\n",
        "            params = {'model_state_dict': model.state_dict(), \n",
        "                      'optimizer_state_dict': optimizer.state_dict(), \n",
        "                      'scheduler_state_dict': scheduler.state_dict}\n",
        "          else:\n",
        "            params = {'model_state_dict': model.state_dict(), \n",
        "                      'optimizer_state_dict': optimizer.state_dict()}\n",
        "          \n",
        "          torch.save(params, 'checkpoint_{}.ckpt'.format(iteration))\n",
        "              \n",
        "        val_accs.append(val_acc)\n",
        "        model.train(True)\n",
        "      \n",
        "      if use_scheduler:\n",
        "        scheduler.step()\n",
        "\n",
        "    print('epoch loss: %f' % epoch_loss)\n",
        "\n",
        "if VALIDATION:\n",
        "    if DEBUG:\n",
        "      fine_tune(X_train, y_train, X_val, y_val, \n",
        "                n_epochs=5, batch_size=8, val_every=5)\n",
        "    else:\n",
        "      fine_tune(X_train, y_train, X_val, y_val, \n",
        "                n_epochs=n_epochs, batch_size=batch_size, val_every=val_every)\n",
        "else:\n",
        "    if DEBUG:\n",
        "      fine_tune(X_train, y_train, X_val=None, y_val=None, \n",
        "                n_epochs=5, batch_size=8, val_every=5)\n",
        "    else:\n",
        "      fine_tune(X_train, y_train, X_val=None, y_val=None, \n",
        "                n_epochs=n_epochs, batch_size=batch_size, val_every=val_every)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "cellView": "form",
        "colab_type": "code",
        "deletable": true,
        "id": "e-qAwemZHQ0U",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "#@title Train (fine-tune) from a checkpoint\n",
        "checkpoint = 1500 #@param {type:\"integer\"}\n",
        "epochs = 4 #@param {type:\"integer\"}\n",
        "learning_rate = 5e-5 #@param {type:\"number\"}\n",
        "\n",
        "def train_from_checkpoint(checkpoint, X_train, y_train, X_val, y_val, n_epochs, batch_size, val_every, learning_rate=1e-4):\n",
        "  model = BERT(num_labels=2)\n",
        "  print('Loading from the checkpoint %d' % checkpoint)\n",
        "  \n",
        "  params = torch.load('checkpoint_{}.ckpt'.format(checkpoint))\n",
        "  model.linear.load_state_dict(params['linear_state_dict'])\n",
        "  optimizer = AdamW(model.parameters())\n",
        "  optimizer.load_state_dict(params['optimizer_state_dict'])\n",
        "  \n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = learning_rate\n",
        "  \n",
        "  print('n_epochs: %d, learning rate: %f' % (n_epochs, learning_rate))\n",
        "\n",
        "  iteration = checkpoint\n",
        "  val_accs = []\n",
        "  running_loss, running_num_iter = 0., 0\n",
        "\n",
        "  for i in range(n_epochs):\n",
        "    epoch_loss = 0.\n",
        "    for X, y in batch_iter(X_train, y_train, tokenizer, batch_size=batch_size):\n",
        "      iteration += 1\n",
        "      running_num_iter += 1\n",
        "\n",
        "      if iteration % 10 == 0:\n",
        "        print('iteration', iteration)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss, _, _ = model(X, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      epoch_loss += loss.item()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      if iteration % val_every == 0 and VALIDATION:\n",
        "        print('loss:', running_loss / running_num_iter)\n",
        "        \n",
        "        running_loss = 0.\n",
        "        running_num_iter = 0\n",
        "\n",
        "        print('begin validation...')\n",
        "        n_correct = 0\n",
        "        n_samples = 0\n",
        "        for X, y in batch_iter(X_val, y_val, tokenizer, batch_size=batch_size):\n",
        "            n_samples += len(X)\n",
        "            _, preds, _ = model(X)\n",
        "            n_correct += torch.sum(preds == y).item()\n",
        "        \n",
        "        val_acc = n_correct / n_samples\n",
        "        print('val acc: %f' % val_acc)\n",
        "        \n",
        "        if len(val_accs) == 0 or max(val_accs) < val_acc:\n",
        "            print('Saving checkpoint...')\n",
        "\n",
        "            params = {\n",
        "                'linear_state_dict': model.linear.state_dict(), \n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "                }\n",
        "            torch.save(params, 'checkpoint_{}.bin'.format(iteration))\n",
        "            #files.download('checkpoint_{}.bin'.format(iteration))\n",
        "        val_accs.append(val_acc)\n",
        "    \n",
        "    print('epoch loss: %f' % epoch_loss)\n",
        "\n",
        "\n",
        "if VALIDATION:\n",
        "    if DEBUG:\n",
        "      train_from_checkpoint(checkpoint, X_train, y_train, X_val, y_val, n_epochs=epochs, batch_size=16, val_every=5, learning_rate=learning_rate)\n",
        "    else:\n",
        "      train_from_checkpoint(checkpoint, X_train, y_train, X_val, y_val, n_epochs=epochs, batch_size=32, val_every=100, learning_rate=learning_rate)\n",
        "else:\n",
        "    if DEBUG:\n",
        "      train_from_checkpoint(checkpoint, X_train, y_train, X_val=None, y_val=None, n_epochs=epochs, batch_size=16, val_every=5, learning_rate=learning_rate)\n",
        "    else:\n",
        "      train_from_checkpoint(checkpoint, X_train, y_train, X_val=None, y_val=None, n_epochs=epochs, batch_size=32, val_every=100, learning_rate=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "qwRXongNgGtE",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "## Load a pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "cellView": "form",
        "colab_type": "code",
        "deletable": true,
        "id": "psqTOngyyJ-B",
        "new_sheet": false,
        "outputId": "8cb6489f-aa00-4a7c-9533-a8c0d404aa81",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "#@title Load from cloud storage\n",
        "checkpoint_name = \"checkpoint_13500_xlnet_large_scheduler.ckpt\" #@param {type:\"string\"}\n",
        "project_id = 'train-on-tpu'\n",
        "bucket_name = 'mreza-tpu-bucket1'\n",
        "auth.authenticate_user()\n",
        "! gcloud config set project {project_id}\n",
        "! gsutil cp gs://{bucket_name}/{checkpoint_name} /content/\n",
        "\n",
        "params = torch.load(checkpoint_name)\n",
        "model = XLNetClassifier('xlnet-large-cased')\n",
        "model.load_state_dict(params['model_state_dict'])\n",
        "model.to(DEVICE)\n",
        "del params"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "Copying gs://mreza-tpu-bucket1/checkpoint_13500_xlnet_large_scheduler.ckpt...\n",
            "- [1 files][  4.0 GiB/  4.0 GiB]   79.3 MiB/s                                   \n",
            "Operation completed over 1 objects/4.0 GiB.                                      \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 699/699 [00:00<00:00, 391587.89B/s]\n",
            "100%|██████████| 1441285815/1441285815 [00:25<00:00, 55556916.97B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "VEDoa7pW2Q2R",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Just to check the contents of bucket:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "hBPbDXYCyilc",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "05cea22c-8ae9-42d1-8618-7110d8dc4b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "! gsutil ls gs://{bucket_name}/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://mreza-tpu-bucket1/checkpoint_13500_xlnet_large_scheduler.ckpt\n",
            "gs://mreza-tpu-bucket1/checkpoint_20500_xlnet_large_wo_scheduler.ckpt\n",
            "gs://mreza-tpu-bucket1/checkpoint_9000_bert_base_wo_scheduler.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "cellView": "form",
        "colab_type": "code",
        "deletable": true,
        "id": "aRsqYXxPgGQC",
        "new_sheet": false,
        "outputId": "5ecafdfc-6845-4fb2-def3-076dc75cf022",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Load model from local checkpoint\n",
        "checkpoint_name = \"checkpoint_13500_xlnet_large_scheduler.ckpt\" #@param {type:\"string\"}\n",
        "print('loading %s' % checkpoint_name)\n",
        "\n",
        "params = torch.load(checkpoint_name)\n",
        "model = XLNetClassifier('xlnet-large-cased')\n",
        "model.load_state_dict(params['model_state_dict'])\n",
        "model.to(DEVICE)\n",
        "del params\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading checkpoint_13500_xlnet_large_scheduler.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "CUGHb7ZB2aCa",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Creating an instance of tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "Sc0yckpu2Y4H",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "outputId": "e33ab07c-240a-4393-8409-d7e31d64d1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 798011/798011 [00:00<00:00, 10178539.44B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "OGnBqHzf3dhc",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### LDA on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "q2ToSw0T3dhe",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Lemmatizing, stemmizing, and removing stopwords:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "Gws9A0Bc3dhf",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result\n",
        "\n",
        "def batch_iter(X, y):\n",
        "    assert len(X) == len(y)\n",
        "    idxs = np.arange(len(X))\n",
        "    np.random.shuffle(idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "nMgJcoTw3dhh",
        "new_sheet": false,
        "outputId": "46605f2c-6d42-48c3-aaac-03901bc77bea",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "test_df = test_df[:5000]\n",
        "\n",
        "X_test = test_df['sentence'].tolist()\n",
        "y_test = test_df['polarity'].tolist()\n",
        "\n",
        "# pre-process the test set to be used for LDA\n",
        "test_df_processed = test_df\n",
        "test_df_processed['sentence'] = test_df['sentence'].apply(preprocess)\n",
        "X_test_lda = test_df_processed['sentence'].tolist()\n",
        "y_test_lda = test_df_processed['polarity'].tolist()\n",
        "\n",
        "print(len(X_test))\n",
        "print(len(X_test_lda))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "NfVSvrxy3dhj",
        "new_sheet": false,
        "outputId": "7f364b14-4603-4e44-b57b-4a4d9bab8c84",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(X_test_lda)\n",
        "print('number of unique tokens:', len(dictionary))\n",
        "\n",
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=10000)\n",
        "print('number of unique tokens after filtering:', len(dictionary))\n",
        "\n",
        "# bag-of-word corpus\n",
        "bow_corpus = [dictionary.doc2bow(text) for text in X_test_lda]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of unique tokens: 23669\n",
            "number of unique tokens after filtering: 3386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "cellView": "form",
        "colab_type": "code",
        "deletable": true,
        "id": "1fEJPkiB02AL",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "#@title LDA model\n",
        "alpha = 0.31 #@param {type:\"raw\"}\n",
        "eta = 0.91 #@param {type:\"raw\"}\n",
        "passes = 10 #@param {type:\"integer\"}\n",
        "num_topics = 8 #@param {type:\"integer\"}\n",
        "np.random.seed(100)\n",
        "lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
        "                                       id2word=dictionary,\n",
        "                                       num_topics=num_topics, \n",
        "                                       random_state=100,\n",
        "                                       chunksize=100,\n",
        "                                       passes=passes,\n",
        "                                       alpha=alpha,\n",
        "                                       eta=eta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "hD_9NQFt3dhm",
        "new_sheet": false,
        "outputId": "c44c89a6-c025-4080-b6a2-6872a97bb122",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=X_test_lda, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Coherence Score:  0.3164130601695836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "Iq3Jen813dhr",
        "new_sheet": false,
        "outputId": "78cb1eb2-b918-478f-e533-6f297cd38304",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.024*\"music\" + 0.015*\"song\" + 0.014*\"danc\" + 0.011*\"comedi\" + 0.010*\"great\" + 0.010*\"sing\" + 0.008*\"jack\" + 0.008*\"star\" + 0.007*\"good\" + 0.007*\"best\"\n",
            "Topic: 1 \n",
            "Words: 0.013*\"kill\" + 0.013*\"horror\" + 0.009*\"scene\" + 0.007*\"murder\" + 0.006*\"get\" + 0.006*\"dead\" + 0.006*\"like\" + 0.005*\"go\" + 0.005*\"killer\" + 0.005*\"end\"\n",
            "Topic: 2 \n",
            "Words: 0.026*\"love\" + 0.020*\"like\" + 0.014*\"watch\" + 0.014*\"think\" + 0.014*\"great\" + 0.012*\"play\" + 0.012*\"time\" + 0.011*\"good\" + 0.011*\"stori\" + 0.010*\"see\"\n",
            "Topic: 3 \n",
            "Words: 0.016*\"seri\" + 0.012*\"episod\" + 0.009*\"version\" + 0.008*\"origin\" + 0.007*\"star\" + 0.007*\"play\" + 0.007*\"releas\" + 0.006*\"anim\" + 0.006*\"year\" + 0.006*\"time\"\n",
            "Topic: 4 \n",
            "Words: 0.011*\"life\" + 0.009*\"peopl\" + 0.008*\"human\" + 0.007*\"live\" + 0.006*\"world\" + 0.006*\"american\" + 0.006*\"know\" + 0.006*\"stori\" + 0.005*\"real\" + 0.005*\"time\"\n",
            "Topic: 5 \n",
            "Words: 0.024*\"like\" + 0.016*\"watch\" + 0.015*\"good\" + 0.013*\"think\" + 0.012*\"time\" + 0.010*\"look\" + 0.010*\"act\" + 0.009*\"peopl\" + 0.009*\"see\" + 0.008*\"know\"\n",
            "Topic: 6 \n",
            "Words: 0.008*\"comedi\" + 0.008*\"georg\" + 0.005*\"work\" + 0.005*\"radio\" + 0.005*\"hospit\" + 0.005*\"boss\" + 0.005*\"talk\" + 0.005*\"scott\" + 0.005*\"joan\" + 0.005*\"stone\"\n",
            "Topic: 7 \n",
            "Words: 0.019*\"charact\" + 0.013*\"stori\" + 0.008*\"time\" + 0.008*\"scene\" + 0.008*\"work\" + 0.007*\"director\" + 0.007*\"perform\" + 0.006*\"like\" + 0.006*\"great\" + 0.005*\"feel\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "bmn1zoFb14FG",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "topics = {}\n",
        "for text_id in range(len(bow_corpus)):\n",
        "  sorted_topics = sorted(lda_model[bow_corpus[text_id]], reverse=True)\n",
        "  t = sorted_topics[0]\n",
        "  topic_index = t[0]\n",
        "  if topics.get(topic_index, None) is None:\n",
        "    topics[topic_index] = [text_id]\n",
        "  else:\n",
        "    topics[topic_index].append(text_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "didzgrUD2ABr",
        "new_sheet": false,
        "outputId": "9e1af6cd-e530-4712-d9ab-1bbc10ba8c84",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for k, v in topics.items():\n",
        "  print('%d documents under topic %d' % (len(v), k))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1108 documents under topic 5\n",
            "3166 documents under topic 7\n",
            "157 documents under topic 4\n",
            "435 documents under topic 6\n",
            "59 documents under topic 2\n",
            "69 documents under topic 3\n",
            "6 documents under topic 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "qTd3g-dD2M-f",
        "new_sheet": false,
        "outputId": "940cec77-50fd-4df6-f8dc-4a97f12bc098",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for key, values in topics.items():\n",
        "  positives = [v for v in values if y_test[v] == 1]\n",
        "  print('topic %d: percentage of documents with positive sentiment: %.2f' % (key, len(positives) / len(values)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic 5: percentage of documents with positive sentiment: 0.28\n",
            "topic 7: percentage of documents with positive sentiment: 0.56\n",
            "topic 4: percentage of documents with positive sentiment: 0.85\n",
            "topic 6: percentage of documents with positive sentiment: 0.42\n",
            "topic 2: percentage of documents with positive sentiment: 0.83\n",
            "topic 3: percentage of documents with positive sentiment: 0.90\n",
            "topic 1: percentage of documents with positive sentiment: 0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "j42v7KuT3diA",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### Extracting the CAV for a concept"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "wrRnK3Me2135",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Using a topic with high percentage of positive documents:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "F2IMSFuu3diA",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "topic = 2\n",
        "\n",
        "concept_examples_idxs = topics[topic]\n",
        "concept_examples = [X_test[i] for i in concept_examples_idxs]\n",
        "\n",
        "other_examples_idxs = [i for i in range(len(X_test)) if i not in concept_examples_idxs]\n",
        "random_examples_idxs = np.random.choice(other_examples_idxs, 100)\n",
        "random_examples = [X_test[i] for i in random_examples_idxs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "ChMO6R333tL2",
        "new_sheet": false,
        "outputId": "63ba8068-962e-43be-eee2-d7b712c2ede3",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "print(len(concept_examples))\n",
        "print(len(random_examples))\n",
        "\n",
        "print(concept_examples[1])\n",
        "print(random_examples[14])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56\n",
            "100\n",
            "I thought this movie was really awesome! One of Drew's best. I am also a fan of Michael Vartan so I thought he was so hot in this movie. Why all the bad reviews. I would want to watch this movie over and over again if I could. I also loved the ending. This movie clearly has shown a smile on my face! I was also surprised that James Franco and Jessica Alba were in it. I love them both so I also highlighted this movie. At the end, when Drew is making the huge comment about the truth it really told the truth of what sometimes happens in High School. Again, the movie was amazing. Defiantly a 10/10. Hope this comment was very useful to any IMDb readers.\n",
            "i just got done watching this movie and i have to say, it was a good film, i loved some of the good guy's and i loved the killer robot but the movie had some hole's in it.<br /><br />the name's of the people in it was kind of..stupid..i think people should of sued the maker's of this movie for how lame it was at the end..the first half hour was good but then it just dragged on and on then i was happy..it was over...but still loved the the killer robot and some of the movie's good guy's in it.<br /><br />i think it was the best two buck's i have ever spent because i do like stupid b-movie's like this one and come on..it is a b-movie everyone.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "ic0MjRGw3diC",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "def train_cav(concept_examples, random_examples, model):\n",
        "    batch_size = 8\n",
        "    \n",
        "    concept_labels = torch.ones([len(concept_examples)])\n",
        "    random_labels = torch.zeros([len(random_examples)])\n",
        "    \n",
        "    concept_repres = []\n",
        "    for X, y in batch_iter(concept_examples, concept_labels, tokenizer, 8):\n",
        "        with torch.no_grad():\n",
        "          _, _, representation = model(X.to(DEVICE))\n",
        "          concept_repres.append(representation[0].sum(dim=0).squeeze())\n",
        "\n",
        "    concept_repres = torch.cat(concept_repres, dim=0).cpu().detach().numpy()\n",
        "    #print('concept representation shape', concept_repres.shape)\n",
        "\n",
        "    random_repres = []\n",
        "    for X, y in batch_iter(random_examples, random_labels, tokenizer, 8):\n",
        "        with torch.no_grad():\n",
        "          _, _, representation = model(X.to(DEVICE))\n",
        "          random_repres.append(representation[0].sum(dim=0).squeeze())\n",
        "    \n",
        "    random_repres = torch.cat(random_repres, dim=0).cpu().detach().numpy()\n",
        "    #print('random representation shape', random_repres.shape)\n",
        "    \n",
        "    concept_labels = concept_labels.cpu().detach().numpy()\n",
        "    random_labels = random_labels.cpu().detach().numpy()\n",
        "    \n",
        "    X = np.vstack([concept_repres, random_repres])\n",
        "    y = np.hstack([concept_labels, random_labels])\n",
        "    \n",
        "    X = np.insert(X, 0, 1, axis=1)\n",
        "    \n",
        "    assert len(X) == len(y)\n",
        "    idxs = np.arange(len(X))\n",
        "    np.random.shuffle(idxs)\n",
        "    X, y = X[idxs], y[idxs]\n",
        "\n",
        "    lm = linear_model.LogisticRegression(solver='lbfgs', max_iter=5000)\n",
        "    lm.fit(X, y)\n",
        "    cav = lm.coef_[0][1:]\n",
        "    \n",
        "    return cav"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "7UoNvsqI2yIa",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Training a single cav:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "aKMcpHYo-csy",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "cav = train_cav(concept_examples, random_examples, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "-vBLepGMzvT3",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Training more than one cav for the sake of statistical significance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "wwXe9ON_eSC-",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "def statistical_testing(topic, num_runs=500):\n",
        "  cavs = []\n",
        "\n",
        "  concept_examples_idxs = topics[topic]\n",
        "  concept_examples = [X_test[i] for i in concept_examples_idxs]\n",
        "  other_examples_idxs = [i for i in range(len(X_test)) if i not in concept_examples_idxs]\n",
        "\n",
        "  for i in range(num_runs):\n",
        "    if i%10 == 0:\n",
        "      print('iteration %d' % i)\n",
        "    \n",
        "    random_examples_idxs = np.random.choice(other_examples_idxs, 500)\n",
        "    random_examples = [X_test[i] for i in random_examples_idxs]\n",
        "    cavs.append(train_cav(concept_examples, random_examples, model))\n",
        "\n",
        "  return cavs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "JxrgH6Xu3diE",
        "new_sheet": false,
        "outputId": "76a8c848-d4b0-4c1d-aa87-c1f24bf3cc9e",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "cavs = statistical_testing(topic=2, num_runs=100)\n",
        "np.save('cavs', cavs)\n",
        "print(len(cavs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "iteration 10\n",
            "iteration 20\n",
            "iteration 30\n",
            "iteration 40\n",
            "iteration 50\n",
            "iteration 60\n",
            "iteration 70\n",
            "iteration 80\n",
            "iteration 90\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "eGXfghtC3diG",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "\"conceptual sensitivty\" for a single example and a desired class and a concept's CAV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "I3OAZkFT3diI",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "def sensitivity(sample, cav, desired_class):\n",
        "  sample = pad([tokenizer.encode(sample[:128], add_special_tokens=True)])\n",
        "  \n",
        "  model.zero_grad()\n",
        "  logits, _, representation = model(torch.tensor(sample).to(DEVICE))\n",
        "\n",
        "  logits[0, desired_class].backward()\n",
        "\n",
        "  grad = model.grad_representation\n",
        "  grad = grad.sum(dim=0).squeeze().cpu().detach().numpy()\n",
        "\n",
        "  sensitivity = np.dot(grad, cav)\n",
        "  \n",
        "  return sensitivity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "nTzTSJclfnzK",
        "new_sheet": false,
        "outputId": "b1f10015-db7d-44d1-f8f1-1ff7f6d5988d",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sensitivity(concept_examples[1], cav, desired_class=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00028777589161624946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "vg5rqRGI3diK",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "### TCAV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "odh7zCwP3diK",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "# a set of inputs\n",
        "def TCAV(examples, desired_class, cav):\n",
        "  sensitivities = []\n",
        "  for example in examples:\n",
        "    sensitivities.append(sensitivity(example, cav, desired_class))\n",
        "  \n",
        "  return len([s for s in sensitivities if s > 0]) / len(examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "Kw7vNuu50Wu-",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Using more than one cav for statistical significance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "07ki6rIX3diM",
        "new_sheet": false,
        "outputId": "68cf3dad-719c-4d6c-dc0a-5281f7156cbb",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tcavs = []\n",
        "positive_idxs = [i for i in range(len(y_test)) if y_test[i] == 1]\n",
        "example_idxs = np.random.choice(positive_idxs, 100)\n",
        "examples = [X_test[idx] for idx in example_idxs]\n",
        "\n",
        "for i in range(len(cavs)):\n",
        "  print(i, end=' ')\n",
        "  tcavs.append(TCAV(examples=examples, desired_class=1, cav=cavs[i]))\n",
        "\n",
        "print()\n",
        "print(tcavs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
            "[0.67, 0.63, 0.68, 0.63, 0.47, 0.62, 0.62, 0.63, 0.61, 0.6, 0.63, 0.59, 0.65, 0.6, 0.6, 0.58, 0.7, 0.7, 0.62, 0.57, 0.69, 0.6, 0.72, 0.71, 0.72, 0.7, 0.65, 0.77, 0.53, 0.68, 0.61, 0.65, 0.57, 0.58, 0.7, 0.64, 0.64, 0.58, 0.71, 0.63, 0.67, 0.62, 0.74, 0.53, 0.67, 0.68, 0.69, 0.66, 0.6, 0.63, 0.6, 0.74, 0.54, 0.58, 0.7, 0.51, 0.66, 0.71, 0.71, 0.58, 0.63, 0.63, 0.65, 0.59, 0.7, 0.65, 0.73, 0.57, 0.68, 0.64, 0.58, 0.63, 0.68, 0.66, 0.66, 0.6, 0.63, 0.67, 0.68, 0.5, 0.73, 0.57, 0.62, 0.64, 0.63, 0.67, 0.66, 0.71, 0.61, 0.71, 0.59, 0.77, 0.61, 0.68, 0.7, 0.72, 0.83, 0.61, 0.65, 0.74]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "bpxOjace4UBA",
        "new_sheet": false,
        "outputId": "49d16aee-5b8a-4124-d702-c84741a82bb2",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(tcavs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6802000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "u6imaTkhypXW",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### Perturbing the representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "x0Qao-hyyvL8",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "Perturbing the representation of a set of examples and investigating its effect on the score of a desired class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "Yv1jl9QvMx4W",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "colab": {}
      },
      "source": [
        "def perturb_representation(model, representation, cav, alpha=1):\n",
        "  representation += alpha * cav\n",
        "  logits, preds = model.forward_from_representation(representation)\n",
        "\n",
        "  return logits, preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "WTvAGNcv_9RC",
        "new_sheet": false,
        "outputId": "cc95a45b-a75d-47f9-fb38-d8f494a52d2b",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = [100, 11, 34, 24, 25, 29, 30]\n",
        "np.random.choice(a, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "colab_type": "text",
        "deletable": true,
        "id": "sgx1X3OKC3UM",
        "new_sheet": false,
        "run_control": {
          "read_only": false
        }
      },
      "source": [
        "#### Computing sensitivity for large sample of inputs (not necessarily with a positive sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "id": "_qlcG8inABXw",
        "new_sheet": false,
        "outputId": "734f22fd-8820-44fa-91d0-fc1298635c3a",
        "run_control": {
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "idxs = np.arange(len(X_test))\n",
        "example_idxs = np.random.choice(idxs, 100)\n",
        "\n",
        "examples = [X_test[idx] for idx in example_idxs]\n",
        "\n",
        "sensitivities = []\n",
        "cav = cavs[0]\n",
        "\n",
        "for example in examples:\n",
        "  sensitivities.append(sensitivity(example, cav, 1))\n",
        "\n",
        "pos_sens = [sens for sens in sensitivities if sens > 0]\n",
        "print(len(pos_sens) / len(sensitivities))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbjgzMOckQA1",
        "colab_type": "text"
      },
      "source": [
        "#### Negative concept"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "WYWQlaVqNq31",
        "colab": {}
      },
      "source": [
        "topic = 5\n",
        "\n",
        "concept_examples_idxs = topics[topic]\n",
        "concept_examples = [X_test[i] for i in concept_examples_idxs]\n",
        "\n",
        "other_examples_idxs = [i for i in range(len(X_test)) if i not in concept_examples_idxs]\n",
        "random_examples_idxs = np.random.choice(other_examples_idxs, 1000)\n",
        "random_examples = [X_test[i] for i in random_examples_idxs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "colab_type": "code",
        "deletable": true,
        "new_sheet": false,
        "outputId": "51d2cee8-efdc-4913-8dab-984d87ced155",
        "run_control": {
          "read_only": false
        },
        "id": "6sJtOwhBNq35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "print(len(concept_examples))\n",
        "print(len(random_examples))\n",
        "\n",
        "print(concept_examples[1])\n",
        "print(random_examples[14])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1108\n",
            "1000\n",
            "being a fan of Bela Lugosi,Boris Karloff,and Lon Chaney Jr i had to see this.what tripe the only thing good about this is the clips of Lugosi,Karloff and Chaney Jr.along with all the vintage clips,that do not gel with the new black and white footage.not even close to Steve martins dead men don't wear plaid,that was done great.with all the technology we have now why was'nt this done better?if you are planning to shell out 5 bucks and some change,be warned this is really bad. but if you like Lugosi Karloff and Chaney Jr then watch their movies instead.even ed wood did better then this one.new actor mark redfield is pretty good as an imitation Bela Lugosi.the clips they use are; the ape,Mr Wong,most dangerous game,lost world,indestructible man. and devil bat.that notorious Bela Lugosi classic.i believe this production was very low budget,and it shows.1 out of 10.\n",
            "Despite having a very pretty leading lady (Rosita Arenas, one of my boy-crushes), the acting and the direction are examples of what NOT to do while making a movie.<br /><br />Placed in southern Mexico, Popoca, the Aztec Mummy (real Aztecs, by the way, DID not made mummies) has been waken up by the lead characters and starts making trouble in Mexico City suburbia, during the first movie (The Aztec Mummy). In this second part, the leading man and woman want to find th mummy and put it in its final resting place (a fireplace would have been my first choice...)<br /><br />Into this appears The Bat, a criminal master-mindless stereotype of a criminal genius who creates a \"human robot\" (some idiot inside a robot SUIT) to control Popoca and (get this) take over the world. The final match between the robot and the mummy is hilarious, some of the worst choreography ever witnessed. The funniest part is that this movie was made and released by a serious Mexican movie studio!<br /><br />The acting is just as awful hearing the movie in Spanish as it is in English (they dubbed the over-acting!). You should watch this movie through MST:3000. The comments are even funnier.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_qZIoB9kve6",
        "colab_type": "code",
        "outputId": "bb34466c-6622-458a-b353-fbfc9bdb2178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "cavs = statistical_testing(topic=5, num_runs=100)\n",
        "np.save('cavs', cavs)\n",
        "print(len(cavs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "iteration 10\n",
            "iteration 20\n",
            "iteration 30\n",
            "iteration 40\n",
            "iteration 50\n",
            "iteration 60\n",
            "iteration 70\n",
            "iteration 80\n",
            "iteration 90\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcSWxfcGlmIv",
        "colab_type": "code",
        "outputId": "22c74743-d2e2-493d-e8d3-15d1023ac808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "idxs = np.arange(len(X_test))\n",
        "example_idxs = np.random.choice(idxs, 100)\n",
        "\n",
        "examples = [X_test[idx] for idx in example_idxs]\n",
        "\n",
        "sensitivities = []\n",
        "cav = cavs[0]\n",
        "\n",
        "for example in examples:\n",
        "  sensitivities.append(sensitivity(example, cav, 1))\n",
        "\n",
        "pos_sens = [sens for sens in sensitivities if sens > 0]\n",
        "print(len(pos_sens) / len(sensitivities))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ACIIsjGSL-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}